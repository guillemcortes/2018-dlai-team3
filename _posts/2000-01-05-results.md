---
title: "Results"
bg: #9AD1F5
color: black
style: center
fa-icon: line-chart
---






## Horse2zebra

After testing the pretrained horse2zebra model and also training a new cycleGAN from zero for those 2 datasets for only 2 epochs, here are the results
We tested this shortly trained model and the pretrained model prepared by the authors of the paper. A glimpse to the result is the following:


<table style="width:100%">
  <tr>
    <th><img src="./img/training/pretrained_n02381460_1010_real_A.png" alt="Real image"/>
	</th>
    <th><img src="./img/training/pretrained_n02381460_1010_fake_B.png" alt="Result with pretrained Horse2zebra model"/></th> 
    <th><img src="./img/training/trained_2e_n02381460_1010_fake_B.png" alt="Result with model trained for 2 epochs"/></th>
  </tr>
  <tr>
  <th>Real image</th>
    <th>Result generated with pretrained Horse2zebra model</th> 
    <th>Result with model trained for 2 epochs</th>
  </tr>
</table>

Those experiments have been performed to get to know the environment in terms of configuration, execution time and limitations, and the code of the CycleGAN.


## Faces to caricatures

In this experiment we aim to train the cycleGAN model for converting from faces to caricatures and viceversa. For the moment we have 3 results: 5 epochs with resizing to 64x64, 5 epochs with 128x128 resizing and 16 epochs with 128x128 resizing.

*Exp2.1: 5 epochs with 64x64*	

| ![](./img/training/64x64/64x_006002_real_A.png ) | 	![](./img/training/64x64/64x_006002_fake_B.png ) |
| ![](./img/training/64x64/64x_006007_real_A.png ) | 	![](./img/training/64x64/64x_006007_fake_B.png) |
| ![](./img/training/64x64/64x_006085_real_A.png) | 	![](./img/training/64x64/64x_006002_fake_B.png ) |


This trained model is not very useful, obviously as the training is very small. It was meant to test for improvement on the training speed.


*Exp2.2: 5 epochs with 128x128*

| ![](./img/training/128x128_5e/006002_real_A.png ) | 	![](./img/training/128x128_5e/006002_fake_B.png ) |
| ![](./img/training/128x128_5e/006007_real_A.png ) | 	![](./img/training/128x128_5e/006007_fake_B.png ) |
| ![](./img/training/128x128_5e/006085_real_A.png ) | 	![](./img/training/128x128_5e/006085_fake_B.png ) |


we get better results than with 64x64, we suspect the networks are not suitable for 64x64 dimension. Still those are not good results.


*Exp2.3: 16 epochs with 128x128*

| ![](./img/training/128x128_16e/006002_real_A.png ) | 	![](./img/training/128x128_16e/006002_fake_B.png ) |
| ![](./img/training/128x128_16e/006007_real_A.png ) | 	![](./img/training/128x128_16e/006007_fake_B.png ) |
| ![](./img/training/128x128_16e/006085_real_A.png ) | 	![](./img/training/128x128_16e/006085_fake_B.png ) |

The Generative A networks seems to be worse than in the beginning.
The Generative B network starts to show better results, up until now it was absolutely unusable, we start to see some more realistic faces generated from caricatures but they are still far from being close to real.
Still shape transformation are almost not present.
We trained for more than 16 epochs and the results are not good.
The loss functions show a dwontrend in the first epochs but then after epoch 10 they oscillate without really increasing or decreasing.
Overall we are not getting generative network A to caricaturize at all, at most it makes a picture of a face appear as a drawing.

## miniCycleGAN

<table style="width:100%">
  <tr>
    <th><img src="./img/GAN_epoch001.png" alt="Epoch001"/></th>
    <th><img src="./img/GAN_epoch050.png" alt="Epoch050"/></th> 
    <th><img src="./img/GAN_generate_animation.gif" alt="Training gif"/></th>
  </tr>
  <tr>
    <th>GAN epoch 01</th>
    <th>GAN epoch 50</th> 
    <th>GAN training gif</th>
  </tr>
</table>

