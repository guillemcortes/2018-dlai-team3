---
title: "introduction"
bg: blue
color: white
fa-icon: quote-left
---

Image to image translation (e.g. style transfer) is a very studied problem in machine learning and many solutions have been proposed and put into production. However all of this solutions rely on having paired data.
With the advent of the GANs, one the most revolutionary concepts in Deep Learning
in the last few years a new "concept" appears: we can create images with  a certain criteria without having paired data.
This leaves the question: How we can keep the content (semantic content) of the original photo but with the style of a new one?

Here's where cycleGANs enters the picture. It's a set of GANS that keep the content of the original image and is capable transforming it between one domain and another.

The aim of this project is to understand one of the newest and more
revolutionary concepts in deep learning: the GANs. And furthermore,
the CycleGANs.

We started studying cicleGAN by studying [the paper that first proposed it](https://arxiv.org/abs/1703.10593) and it's network. This made us realize in order to understand cycleGANs we needed to understand the problem it attempts to resolve and the technology it's been built upon.


