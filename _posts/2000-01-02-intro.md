---
title: "introduction"
bg: blue
color: white
fa-icon: quote-left
---

Image to image translation (e.g. style transfer) is something possible and 
widely used, but a paired data is required for training the models.
With the advent of the GANs, the most revolutionary concept in Deep Learning
in the last few years (posar la referencia de goodfellow que tenim a les diapos)
a new "concept" appears: we can create images with  a determined style/object
whatever without having paired data. But the question is: How we can keep the 
content (semantic content) of the original photo but with the style of another 
one? (afegir foto difer√®ncia paired-unpaired data).

LA solucio son les cycleGANs, un determinat tipus de GANs que mantenen el 
contingut de la imatge original i son capaces de transformar aquest contingut a 
un altre domini.

### Ezequiel part SOLUTIONS + prons & cons
- Style transfer
- GANs

The aim of this project is to understand one of the newest and more
revolutionary concepts in deep learning: the GANs. And furthermore,
the CycleGANs.

Our project is split in two scopes:
- Replicate [CycleGAN](https://arxiv.org/pdf/1703.10593.pdf) results.
- Implement a "Hello World" GAN & CycleGAN from scratch.

THE 2 SCOPES TO BE DETAILED BELOW:
